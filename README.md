#### Workflow for the LLR Analysis including our new `Nt=5` datasets

This is for now a work-in-progress. 
This code assumes that julia is installed. 
No LaTeX is required.

As of now julia-1.10.4 from conda does not work with this code. But we probably don't need it since there are no dependencies outside of julia (except for `zstd` and the optional `ps2pdf` but we can change that).

The raw data and metadata can be downloaded from OneDrive using wget.
```
wget -c "https://swanseauniversity-my.sharepoint.com/:u:/g/personal/fabian_zierler_swansea_ac_uk/EeG7dzwRwLpCsVQV7u_VVjwBxcObi1r3AKJdxLbQpYHVRg?e=PUcctg&download=1" -O ./llr_data.tar.zst
```

Alternatively, the archive is on DiaL3 in the shared directory if you want to download it using rsync. The archive `llr_data.tar.zst` has been created using the `--rsyncable` flag. 

Decompress the archive. After decompression the raw data takes up ~120GB of space. 
Place `metadata` and `raw_data` into the repo's top level directory.

The plots and tables are generated by executing `bash main.sh` starting from the raw logs.

The total runtime on my laptop (i7-1355U) on a single core is:
```
real	22m38.873s
user	20m30.986s
sys	2m0.809s
```
