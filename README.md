# Workflow for the LLR Analysis including our new `Nt=5` datasets

This is for now a work-in-progress.
This code assumes that julia is installed.
No LaTeX is required.

We provide a conda environment file that specifies all required dependencies.
This should work for the `osx-64`, `osx-arm64` and `linux-64`.
It can be activated using:

```
conda env create -f environment.yml
```

The raw data and metadata can be downloaded from OneDrive using wget.

```
wget -c "https://swanseauniversity-my.sharepoint.com/:u:/g/personal/fabian_zierler_swansea_ac_uk/EeG7dzwRwLpCsVQV7u_VVjwBxcObi1r3AKJdxLbQpYHVRg?e=PUcctg&download=1" -O ./llr_data.tar.zst
```

Alternatively,
the archive is on DiaL3 in the shared directory
if you want to download it using rsync.
The archive `llr_data.tar.zst` has been created using the `--rsyncable` flag.

Decompress the archive.
After decompression the raw data takes up ~120GB of space.
Place `metadata` and `raw_data` into the repo's top level directory.

The plots and tables are generated by executing

```
snakemake --use-conda --cores all
```

starting from the raw logs.

The total runtime on my laptop (i7-1355U) on a single core is:

```
real    22m38.873s
user    20m30.986s
sys     2m0.809s
```
